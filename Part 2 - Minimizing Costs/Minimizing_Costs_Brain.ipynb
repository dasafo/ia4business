{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Brain\n",
    "\n",
    "We are going to build a neuronal network like this:\n",
    "\n",
    "<img src=\"Recursos/er_neuronal.jpg\" width=\"800\">\n",
    "\n",
    "### Import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "input}"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the brain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def __init__(self, learning_rate = 0.001, number_actions = 5):\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # INPUT LAYER FORMED BY INPUT STATES\n",
    "        states = Input(shape = (3,))\n",
    "\n",
    "        # TWO HIDDEN LAYERS TOTALLY CONNECTED\n",
    "        x = Dense(units = 64, activation = 'sigmoid')(states)\n",
    "        x = Dropout(rate = 0.1)(x) #during training in each iteration 10% of neurons will be randomly turned off\n",
    "        y = Dense(units = 32, activation = 'sigmoid')(x)\n",
    "        y = Dropout(rate = 0.1)(y) #during training in each iteration 10% of neurons will be randomly turned off\n",
    "\n",
    "        # OUTPUT LAYER TOTALLY CONNECTED TO THE LAST HIDDEN LAYER\n",
    "        q_values = Dense(units = number_actions, activation = 'softmax')(y)\n",
    "\n",
    "        # ENSAMBLAR LA ARQUITECTURA COMPLETA EN UN MODELO DE KERAS \n",
    "        self.model = Model(inputs = states, outputs = q_values)\n",
    "\n",
    "        # COMPILING THE MODEL WITH THE MEAN SQUARE ERROR LOSS FUNCTION(MSE) AND THE OPTIMIZER (Adam)\n",
    "        self.model.compile(loss = 'mse', optimizer = Adam(lr = learning_rate))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
